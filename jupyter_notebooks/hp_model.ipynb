{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataPipeline\n",
    "from tensorflow import data, nn, summary\n",
    "from tensorflow import summary\n",
    "from tensorflow.keras import layers, optimizers, metrics, models, regularizers\n",
    "from tensorboard.plugins.hparams import api as hp\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning\n",
    "This notebook uses the keras tuner to find the best "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4753046 df_training examples\n",
      "264059 validation examples\n",
      "264058 df_test examples\n",
      "\n",
      "create train ds\n",
      "create val ds\n",
      "create test ds\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "TOTAL_SAMPLES = 5997886\n",
    "SUB_SAMPLE_SIZE = 5997886\n",
    "TRAINING_SIZE = SUB_SAMPLE_SIZE * 0.9\n",
    "DEVIATION = 0.05\n",
    "PATIENCE = 10\n",
    "EPOCHS = 10000\n",
    "\n",
    "data = DataPipeline.DataPipeline(\n",
    "  TOTAL_SAMPLES, SUB_SAMPLE_SIZE, TRAINING_SIZE, 1024, DEVIATION, ragged=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "HP_BATCH_SIZE = hp.HParam('batch_size', hp.Discrete([256, 512, 1024, 2048, 4096, 8192, pow(2, 14), pow(2, 15), pow(2, 16)]))\n",
    "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.1, 0.5))\n",
    "HP_LREG = hp.HParam('l2_reg', hp.Discrete([1e-5, 1e-4, 0.01]))\n",
    "HP_NUM_UNITS_L1 = hp.HParam('num_neurons1', hp.Discrete([16, 32, 64, 128, 256]))\n",
    "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['adam', 'sgd']))\n",
    "\n",
    "METRIC_PRC = 'prc'  # precision-recall curve\n",
    "\n",
    "with summary.create_file_writer('logs/hparam_tuning').as_default():\n",
    "  hp.hparams_config(\n",
    "    hparams=[HP_NUM_UNITS_L1, HP_LREG, HP_BATCH_SIZE, HP_DROPOUT, HP_OPTIMIZER],\n",
    "    metrics=[hp.Metric(METRIC_PRC, display_name='PRC')],\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_model(hparams, num_units):\n",
    "  model = models.Sequential([\n",
    "    layers.Dense(hparams[HP_NUM_UNITS_L1], activation=nn.relu, kernel_regularizer=regularizers.l2(HP_LREG)),\n",
    "    layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    layers.Dense(num_units-(num_units/2), activation=nn.relu, kernel_regularizer=regularizers.l2(HP_LREG)),\n",
    "    layers.Dropout(hparams[HP_DROPOUT]),\n",
    "    layers.Dense(1, activation=nn.sigmoid),\n",
    "  ])\n",
    "  model.compile(\n",
    "      optimizer=hparams[HP_OPTIMIZER],\n",
    "      loss='binary_crossentropy',\n",
    "      metrics=[metrics.AUC(name='prc', curve='PR')],\n",
    "  )\n",
    "  \n",
    "  model.fit(\n",
    "    data.train_ds,\n",
    "    epochs=50,\n",
    "    batch_size=HP_BATCH_SIZE) # Run with 1 epoch to speed things up for demo purposes\n",
    "  \n",
    "  print(model.metrics_names)\n",
    "  _,prc = model.evaluate(data.test, data.test_labels)\n",
    "  \n",
    "  return prc\n",
    "\n",
    "def run(run_dir, hparams, num_units):\n",
    "  with summary.create_file_writer(run_dir).as_default():\n",
    "    hp.hparams(hparams)  # record the values used in this trial\n",
    "    prc = train_test_model(hparams, num_units)\n",
    "    summary.scalar(METRIC_PRC, prc, step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_num = 0\n",
    "\n",
    "for num_units in HP_NUM_UNITS_L1.domain.values:\n",
    "  for batch_size  in HP_BATCH_SIZE.domain.values:\n",
    "    for lreg  in HP_LREG.domain.values:\n",
    "      for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
    "        for optimizer in HP_OPTIMIZER.domain.values:\n",
    "          hparams = {\n",
    "              HP_NUM_UNITS_L1: num_units,\n",
    "              HP_LREG: lreg,\n",
    "              HP_BATCH_SIZE: batch_size,\n",
    "              HP_DROPOUT: dropout_rate,\n",
    "              HP_OPTIMIZER: optimizer,\n",
    "          }\n",
    "          run_name = \"run-%d\" % session_num\n",
    "          print('--- Starting trial: %s' % run_name)\n",
    "          print({h.name: hparams[h] for h in hparams})\n",
    "          run('logs/hparam_tuning/' + run_name, hparams, num_units)\n",
    "          session_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    5693697\n",
       "1.0     304189\n",
       "Name: NEO, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.df['NEO'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/hparam_tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('tfmetal')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7 | packaged by conda-forge | (main, Nov 21 2022, 13:21:27) [Clang 14.0.6 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "40e28a4c659ce78843134892121944fbceeae2bfa11b2d4f92c62b1a09965add"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
